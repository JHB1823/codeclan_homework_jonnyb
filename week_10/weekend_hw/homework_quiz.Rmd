---
title: "R Notebook"
output: html_notebook
---

# Quiz

Answer - Over-fitting. Too many variables.

# Question_2

If I have two models, one with an AIC score of 34,902 and the other with an 
AIC score of 33,559 which model should I use?

AIC score of 33,559

# Question_3

I have two models, the first with: r-squared: 0.44, adjusted r-squared: 0.43. 
The second with: r-squared: 0.47, adjusted r-squared: 0.41. Which one 
should I use?

The second

# Question_4

I have a model with the following errors: RMSE error on test set: 10.3, RMSE 
error on training data: 10.4. Do you think this model is over-fitting?

Yes

# Question_5

How does k-fold validation work?

?

# Question_6

What is a validation set? When do you need one?

A validation dataset is a sample of data held back from training 
your model that is used to give an estimate of model accuracy.  

# Question 7

Describe how backwards selection works.

Backwards selection starts with a model that contains all the possible
predictors in the data set. You would then one by one remove the predictors
that lower the r squared value by the least amount each time 

# Question 8

Describe how best subset selection works.

to find the best subset we must compare all the models available
to see which one best fits.


# Question 9

It is estimated on 5% of model projects end up being deployed. What actions 
can you take to maximise the likelihood of your model being deployed?

# Question 10

What metric could you use to confirm that the recent population is similar 
to the development population?

# Question 11

How is the Population Stability Index defined? What does this mean in words?

Population Statistic Index is a statistic that measures 
how much a variable has shifted over time. it is also a value used to monitor 
ho appropriate it is to use a specific model in term of a current population.

# Question 12

Above what PSI value might we need to start to consider rebuilding or 
re-calibrating the model

A PSI greater than 0.25 will mean we have to consider a new model.

# Question 13

What are the common errors that can crop up when implementing a model?




# Question 14

After performance monitoring, if we find that the discrimination is still 
satisfactory but the accuracy has deteriorated, what is the recommended action?

# Question 15

Why is it important to have a unique model identifier for each model?


# Question 16

Why is it important to document the modelling rationale and approach?

